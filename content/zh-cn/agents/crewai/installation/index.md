---
title: "å®‰è£…"
linkTitle: "å®‰è£…"
weight: 20
date: 2025-11-13
description: >
  crewAI å®‰è£…
---

https://docs.crewai.com/en/installation

----

## å‡†å¤‡å·¥ä½œ

### å®‰è£… uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

## å®‰è£… CrewAI

```bash
uv tool install crewai
```

å®‰è£…å®ŒæˆåéªŒè¯ï¼š

```bash
uv tool list
```

å¯ä»¥çœ‹åˆ°è¾“å‡º:

```bash
crewai v1.6.1
- crewai
```

## æ›´æ–°

å¦‚æœéœ€è¦æ›´æ–°ç‰ˆæœ¬ï¼Œå¯ä»¥ï¼š

```bash
uv tool install crewai --upgrade
```

## åˆ›å»ºæµ‹è¯•é¡¹ç›®

```bash
mkdir -p ~/work/code/agents/crewai
cd ~/work/code/agents/crewai
crewai create crew testproject
```

æŒ‰ç…§æç¤ºé€‰æ‹©ï¼š

```bash

Creating folder testproject...
Cache expired or not found. Fetching provider data from the web...
Downloading  [####################################]  961688/50589
Select a provider to set up:
1. openai
2. anthropic
3. gemini
4. nvidia_nim
5. groq
6. huggingface
7. ollama
8. watson
9. bedrock
10. azure
11. cerebras
12. sambanova
13. other
q. Quit
Enter the number of your choice or 'q' to quit: 1
Select a model to use for Openai:
1. gpt-4
2. gpt-4.1
3. gpt-4.1-mini-2025-04-14
4. gpt-4.1-nano-2025-04-14
5. gpt-4o
6. gpt-4o-mini
7. o1-mini
8. o1-preview
q. Quit
Enter the number of your choice or 'q' to quit: 2
Enter your OPENAI API key (press Enter to skip): 
API keys and model saved to .env file
Selected model: gpt-4.1
  - Created testproject/.gitignore
  - Created testproject/pyproject.toml
  - Created testproject/README.md
  - Created testproject/knowledge/user_preference.txt
  - Created testproject/src/testproject/__init__.py
  - Created testproject/src/testproject/main.py
  - Created testproject/src/testproject/crew.py
  - Created testproject/src/testproject/tools/custom_tool.py
  - Created testproject/src/testproject/tools/__init__.py
  - Created testproject/src/testproject/config/agents.yaml
  - Created testproject/src/testproject/config/tasks.yaml
Crew testproject created successfully!
```

å®é™…é¡¹ç›®ç»“æ„ï¼š

```bash
.
â””â”€â”€ testproject
    â”œâ”€â”€ knowledge
    â”‚Â Â  â””â”€â”€ user_preference.txt
    â”œâ”€â”€ pyproject.toml
    â”œâ”€â”€ README.md
    â”œâ”€â”€ src
    â”‚Â Â  â””â”€â”€ testproject
    â”‚Â Â      â”œâ”€â”€ config
    â”‚Â Â      â”‚Â Â  â”œâ”€â”€ agents.yaml
    â”‚Â Â      â”‚Â Â  â””â”€â”€ tasks.yaml
    â”‚Â Â      â”œâ”€â”€ crew.py
    â”‚Â Â      â”œâ”€â”€ __init__.py
    â”‚Â Â      â”œâ”€â”€ main.py
    â”‚Â Â      â””â”€â”€ tools
    â”‚Â Â          â”œâ”€â”€ custom_tool.py
    â”‚Â Â          â””â”€â”€ __init__.py
    â””â”€â”€ tests

8 directories, 10 files
```

æ‰§è¡Œ install å‘½ä»¤æ¥å®‰è£…å„ç§ä¾èµ–ï¼š

```bash
crewai install
```

åˆ›å»º `.env` æ–‡ä»¶ï¼Œå†…å®¹ä¸ºï¼š

```bash
MODEL=openai/gpt-4.1
OPENAI_API_KEY=sk-or-v1-3d32348b8f97ab78a2510f0b60xxxxxxxxxxxxxxxxxxxxxxxxxdd2
OPENAI_API_BASE=https://openrouter.ai/api/v1
```

è¿™é‡Œæˆ‘ç”¨ openrouter æ¥æ›¿ä»£ openaiã€‚

```bash
cd ~/work/code/agents/crewai/testproject
crewai run
```

è¾“å‡ºéå¸¸çš„é•¿ï¼š

```bash
Running the Crew
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Execution Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                      â”‚
â”‚  Crew Execution Started                                                                                              â”‚
â”‚  Name: crew                                                                                                          â”‚
â”‚  ID: 92af3cd2-638e-4e6a-b014-54b7aafc216c                                                                            â”‚
â”‚  Tool Args:                                                                                                          â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸš€ Crew: crew
â””â”€â”€ ğŸ“‹ Task: research_task (ID: d0325f3f-b890-4bf5-b973-f216ff60e939)
    Status: Executing Task...
    â””â”€â”€ ğŸ§  Thinking...
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤– Agent Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                      â”‚
â”‚  Agent: AI LLMs Senior Data Researcher                                                                               â”‚
â”‚                                                                                                                      â”‚
â”‚  Task: Conduct a thorough research about AI LLMs Make sure you find any interesting and relevant information given   â”‚
â”‚  the current year is 2025.                                                                                           â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯


ğŸš€ Crew: crew
â””â”€â”€ ğŸ“‹ Task: research_task (ID: d0325f3f-b890-4bf5-b973-f216ff60e939)
    Assigned to: AI LLMs Senior Data Researcher
    
    Status: âœ… Completed
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Agent Final Answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                      â”‚
â”‚  Agent: AI LLMs Senior Data Researcher                                                                               â”‚
â”‚                                                                                                                      â”‚
â”‚  Final Answer:                                                                                                       â”‚
â”‚  - 1. **Multimodal LLMs Go Mainstream**: Large language models in 2025 now routinely integrate text, images, video,  â”‚
â”‚  audio, and even code, leading to â€œunifiedâ€ models (like GPT-5, Gemini Ultra, and OpenAI's multimodal offerings)     â”‚
â”‚  capable of comprehending and generating across modalities without special prompts.                                  â”‚
â”‚                                                                                                                      â”‚
â”‚  - 2. **Agentic LLMs & Autonomous Reasoning**: Leading LLMs incorporate agentic capabilities for complex planning,   â”‚
â”‚  tool use, self-correction, and contextual adaptation, enabling them to accomplish multi-step tasks, act on web      â”‚
â”‚  data, and interact with external APIs safely and reliably.                                                          â”‚
â”‚                                                                                                                      â”‚
â”‚  - 3. **Open-Source Advancements**: Projects like Metaâ€™s Llama 3 and Mistralâ€™s Mixtral families have reached         â”‚
â”‚  competitive or superior performance compared to proprietary counterparts, democratizing access to cutting-edge      â”‚
â”‚  LLMs with permissive licensingâ€”spurring grassroots innovation and wide deployment.                                  â”‚
â”‚                                                                                                                      â”‚
â”‚  - 4. **Fine-Tuning and Customization at Scale**: New approaches such as Differential Instruction Tuning, Reward     â”‚
â”‚  Modeling, and efficient Domain Adaptation allow organizations to rapidly specialize LLMs for legal, medical,        â”‚
â”‚  scientific, and enterprise applications with unprecedented accuracy and safety.                                     â”‚
â”‚                                                                                                                      â”‚
â”‚  - 5. **Ethics, Safety, and Alignment Breakthroughs**: As LLMs grow in complexity, novel alignment techniques        â”‚
â”‚  (Constitutional AI v2, multi-agent oversight, universal red-teaming) and robust watermarking/testing protocols      â”‚
â”‚  have substantially reduced toxic, biased, or hallucinated outputs, and improved explainability.                     â”‚
â”‚                                                                                                                      â”‚
â”‚  - 6. **Real-Time Reasoning & Edge Deployment**: Thanks to algorithmic and hardware advances (Transformers with      â”‚
â”‚  sparse attention, quantization, memory-efficient inference), powerful LLMs are now able to run on edge              â”‚
â”‚  devicesâ€”from smartphones to industrial IoTâ€”enabling private, low-latency AI.                                        â”‚
â”‚                                                                                                                      â”‚
â”‚  - 7. **Ultra-Long Context Windows**: Models such as GPT-5 and Claude 3 Opus support context windows upwards of 1    â”‚
â”‚  million tokens, facilitating analysis and synthesis across entire books, massive codebases, and complex,            â”‚
â”‚  continuous conversations.                                                                                           â”‚
â”‚                                                                                                                      â”‚
â”‚  - 8. **AI-Powered Research & Discovery**: LLMs are now core assistants in science and engineering, accelerating     â”‚
â”‚  hypothesis generation, literature review, code synthesis, simulation, and experiment design in pharmaceuticals,     â”‚
â”‚  climate modeling, mathematics, and beyond.                                                                          â”‚
â”‚                                                                                                                      â”‚
â”‚  - 9. **Multilingual Capabilities and Global Expansion**: State-of-the-art LLMs boast fluent comprehension and       â”‚
â”‚  generation in 200+ languages, with dialect and context awareness, breaking down language barriers for education,    â”‚
â”‚  commerce, and international collaboration.                                                                          â”‚
â”‚                                                                                                                      â”‚
â”‚  - 10. **Personalization and Privacy**: Advances in federated learning, on-device fine-tuning, and                   â”‚
â”‚  privacy-preserving inference allow users to privately adapt LLMs to their personal style, preferences, and          â”‚
â”‚  knowledgeâ€”without ever sending sensitive data to the cloud.                                                         â”‚
â”‚                                                                                                                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Task Completion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                      â”‚
â”‚  Task Completed                                                                                                      â”‚
â”‚  Name: research_task                                                                                                 â”‚
â”‚  Agent: AI LLMs Senior Data Researcher                                                                               â”‚
â”‚                                                                                                                      â”‚
â”‚  Tool Args:                                                                                                          â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸš€ Crew: crew
â”œâ”€â”€ ğŸ“‹ Task: research_task (ID: d0325f3f-b890-4bf5-b973-f216ff60e939)
â”‚   Assigned to: AI LLMs Senior Data Researcher
â”‚   
â”‚   Status: âœ… Completed
â”‚   â””â”€â”€ ğŸ§  Thinking...
â””â”€â”€ ğŸ“‹ Task: reporting_task (ID: aa65f26c-55ae-4d73-9cd6-4541403295c0)
    Status: Executing Task...
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ¤– Agent Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                      â”‚
â”‚  Agent: AI LLMs Reporting Analyst                                                                                    â”‚
â”‚                                                                                                                      â”‚
â”‚  Task: Review the context you got and expand each topic into a full section for a report. Make sure the report is    â”‚
â”‚  detailed and contains any and all relevant information.                                                             â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯


ğŸš€ Crew: crew
â”œâ”€â”€ ğŸ“‹ Task: research_task (ID: d0325f3f-b890-4bf5-b973-f216ff60e939)
â”‚   Assigned to: AI LLMs Senior Data Researcher
â”‚   
â”‚   Status: âœ… Completed
â””â”€â”€ ğŸ“‹ Task: reporting_task (ID: aa65f26c-55ae-4d73-9cd6-4541403295c0)
    Status: Executing Task...
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… Agent Final Answer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                                   â”‚
â”‚  Agent: AI LLMs Reporting Analyst                                                                                                 â”‚
â”‚                                                                                                                                   â”‚
â”‚  Final Answer:                                                                                                                    â”‚
â”‚  # 2025 AI LLM Landscape: In-Depth Report                                                                                         â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 1. Multimodal LLMs Go Mainstream                                                                                              â”‚
â”‚                                                                                                                                   â”‚
â”‚  The year 2025 marks the full mainstream adoption of multimodal Large Language Models (LLMs), which now natively integrate text,  â”‚
â”‚  images, video, audio, and code within a unified architecture. Pioneering models such as GPT-5, Gemini Ultra, and the latest      â”‚
â”‚  offerings from OpenAI and Anthropic represent a transformative leap from text-only systems to truly universal models. These      â”‚
â”‚  models can seamlessly interpret, combine, and generate across diverse data types without requiring users to issue special        â”‚
â”‚  prompts or indicate the mode of information. For example, a physician can upload a radiology image, an audio dictation, and a    â”‚
â”‚  written case file, allowing the LLM to synthesize findings into a unified diagnostic report. In creative work, a user might ask  â”‚
â”‚  for a narrated storyboard with corresponding visuals and audio cues, all within a single conversational thread. This             â”‚
â”‚  convergence has made LLMs indispensable for multimedia content creation, data analysis, accessibility solutions, and real-world  â”‚
â”‚  task execution across industries.                                                                                                â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 2. Agentic LLMs & Autonomous Reasoning                                                                                        â”‚
â”‚                                                                                                                                   â”‚
â”‚  Modern LLMs are increasingly â€œagenticâ€â€”capable of autonomous reasoning, long-range planning, and dynamic interaction with        â”‚
â”‚  digital environments. Agentic LLMs can now devise multi-step plans, self-assess their actions, and execute complex workflows by  â”‚
â”‚  leveraging external APIs, web search, databases, and software tools. Key advances include toolformer models with integrated      â”‚
â”‚  plug-ins, self-correction and fallback mechanisms, as well as risk-based monitoring for operational safety. For instance, these  â”‚
â”‚  agentic models can automatically draft and send personalized email campaigns, analyze incoming responses, adapt messaging        â”‚
â”‚  strategies, and escalate exceptionsâ€”all with minimal human intervention. Safety protocols ensure that agentic LLMs reliably      â”‚
â”‚  handle web data, respect privacy boundaries, and maintain audit trails, making them suitable for high-stakes applications in     â”‚
â”‚  research, enterprise, and customer engagement.                                                                                   â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 3. Open-Source Advancements                                                                                                   â”‚
â”‚                                                                                                                                   â”‚
â”‚  Open-source LLMs have evolved rapidly, with Metaâ€™s Llama 3 and Mistralâ€™s Mixtral families delivering performance that matches    â”‚
â”‚  or exceeds major proprietary models on benchmarks of accuracy, efficiency, and adaptability. These models are released under     â”‚
â”‚  permissive licenses, fueling an explosion of grassroots contributions, community-driven research, and corporate adoption.        â”‚
â”‚  Open-source LLMs enable broader experimentation with model architectures, transparency, and custom deployment, lowering          â”‚
â”‚  barriers to innovation. This democratization of technology supports local language support, domain-specific tuning, and reduced  â”‚
â”‚  cost for startups and non-profit organizations. In 2025, government agencies, healthcare providers, and independent developers   â”‚
â”‚  increasingly rely upon open LLMs to craft solutions tailored to regional, ethical, and regulatory requirements.                  â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 4. Fine-Tuning and Customization at Scale                                                                                     â”‚
â”‚                                                                                                                                   â”‚
â”‚  The latest techniques in LLM specialization enable rapid, scalable, and secure adaptation for highly specific workflows or       â”‚
â”‚  domains. Differential Instruction Tuning allows LLMs to adjust to nuanced user instructions or evolving best practices without   â”‚
â”‚  full retraining. Reward Modeling integrates reinforcement learning from human or expert feedback to align LLM responses with     â”‚
â”‚  organizational values or compliance needs. Domain Adaptation leverages small, curated corpora or expert-in-the-loop corrections  â”‚
â”‚  for precision in fields such as finance, law, and medicine. These fine-tuning methods unlock state-of-the-art performance on     â”‚
â”‚  tailored tasksâ€”legal contract drafting, scientific literature review, or technical troubleshootingâ€”while preserving safety and   â”‚
â”‚  general language capabilities. Combined with improved data privacy protocols, this enables widespread enterprise and             â”‚
â”‚  vertical-market deployment.                                                                                                      â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 5. Ethics, Safety, and Alignment Breakthroughs                                                                                â”‚
â”‚                                                                                                                                   â”‚
â”‚  As LLMs increase in sophistication and reach, significant breakthroughs have occurred in ensuring ethical operation,             â”‚
â”‚  robustness, and user trust. Enhanced alignment strategiesâ€”such as Constitutional AI v2, which encodes explicit ethical           â”‚
â”‚  frameworks, and multi-agent oversight systemsâ€”provide continual safety checks and adversarial testing. Universal red-teaming     â”‚
â”‚  networks constantly probe for undesirable outputs. Built-in watermarking and robust traceability mechanisms attest to the        â”‚
â”‚  provenance and integrity of generated content. Improved explainability methods offer transparency into model decision-making,    â”‚
â”‚  facilitating responsible integration into regulated environments. As a result, rates of toxic, biased, or hallucinated outputs   â”‚
â”‚  have dropped precipitously, while accountability and compliance have risen, paving the way for safe, large-scale deployment.     â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 6. Real-Time Reasoning & Edge Deployment                                                                                      â”‚
â”‚                                                                                                                                   â”‚
â”‚  Advancements in both algorithms (e.g., sparse Transformers, quantization, retrieval-augmented generation) and hardware           â”‚
â”‚  (optimized AI accelerators) have enabled powerful LLMs to operate efficiently on edge devices. Smartphones, medical              â”‚
â”‚  instruments, autonomous machinery, and industrial IoT systems now run real-time LLM inference, preserving privacy, lowering      â”‚
â”‚  latency, and ensuring continuous operation even without cloud connectivity. For example, edge-deployed LLMs power intelligent    â”‚
â”‚  voice assistants, in-car navigation and diagnostics, and privacy-preserving wearable health monitors. These solutions are        â”‚
â”‚  resilient, highly available, and adapt to bandwidth or regulatory constraints, decentralizing AI and supporting new markets and  â”‚
â”‚  use cases.                                                                                                                       â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 7. Ultra-Long Context Windows                                                                                                 â”‚
â”‚                                                                                                                                   â”‚
â”‚  The expansion of LLM context windows to one million tokens (as in GPT-5 and Claude 3 Opus) has revolutionized how machines       â”‚
â”‚  process and connect information. These ultra-long context capabilities allow for the seamless ingestion and synthesis of entire  â”‚
â”‚  books, massive technical documentation, code repositories, full legal contracts, or multi-hour transcripts within a single       â”‚
â”‚  session. This fundamentally enhances long-form reasoning, document understanding, and persistent conversational memory. Use      â”‚
â”‚  cases include end-to-end review of clinical trials, comprehensive due diligence in finance, and lifelike, multi-session          â”‚
â”‚  personal assistants. The technical advances rely on memory-efficient inference and context-aware retrieval techniques,           â”‚
â”‚  maintaining high relevance, accuracy, and response times despite the scale.                                                      â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 8. AI-Powered Research & Discovery                                                                                            â”‚
â”‚                                                                                                                                   â”‚
â”‚  Modern LLMs have become essential assistants in scientific and engineering research, accelerating nearly every phase of the      â”‚
â”‚  discovery process. They autonomously generate hypotheses, aggregate and synthesize literature, design and simulate experiments,  â”‚
â”‚  analyze datasets, and draft publications. In pharmaceuticals, LLMs help identify new molecular structures, predict outcomes of   â”‚
â”‚  drug trials, and suggest modifications for increased efficacy. In climate science, they aid in modeling, scenario analysis, and  â”‚
â”‚  policy simulation. In mathematics and engineering, LLMs generate proofs, suggest optimization strategies, and support complex    â”‚
â”‚  design thinking. This synergy has shortened the cycle from research question to actionable insight, fueling rapid progress       â”‚
â”‚  across disciplines.                                                                                                              â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 9. Multilingual Capabilities and Global Expansion                                                                             â”‚
â”‚                                                                                                                                   â”‚
â”‚  State-of-the-art LLMs now deliver real-time, nuanced comprehension and generation in over 200 languagesâ€”covering regional        â”‚
â”‚  dialects, technical jargon, and cultural context. This profound multilingual ability breaks down language barriers for global    â”‚
â”‚  collaboration in education, commerce, healthcare, and government. Automated translation and summarization platforms,             â”‚
â”‚  globally-aware customer service agents, and context-sensitive educational tools empower individuals and businesses to            â”‚
â”‚  communicate fluidly across borders. For international partnerships and remote working environments, the LLMâ€™s ability to adapt   â”‚
â”‚  to local context and etiquette ensures effective, respectful, and precise interactions.                                          â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 10. Personalization and Privacy                                                                                               â”‚
â”‚                                                                                                                                   â”‚
â”‚  The interplay of federated learning, on-device training, and privacy-preserving inference empowers users to maintain control     â”‚
â”‚  and confidentiality over their data while harnessing LLM personalization. Individuals and organizations can now tailor LLMs to   â”‚
â”‚  recognize specific terminologies, communication styles, interests, and proprietary knowledge, with all updates occurring         â”‚
â”‚  locally. Sensitive dataâ€”such as medical histories, financial information, and personal communicationsâ€”does not leave the userâ€™s  â”‚
â”‚  device, ensuring compliance with strict privacy regulations (e.g., GDPR, HIPAA). This private adaptation unlocks deeply          â”‚
â”‚  personalized AI-driven experiences: custom writing assistants, domain-specific advisors, and user-aware automation across        â”‚
â”‚  personal and professional domains.                                                                                               â”‚
â”‚                                                                                                                                   â”‚
â”‚  ---                                                                                                                              â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## Conclusion                                                                                                                    â”‚
â”‚                                                                                                                                   â”‚
â”‚  The convergence of these ten trends has catapulted LLMs from experimental systems to omnipresent, transformative technologies    â”‚
â”‚  in 2025. Multimodality, agentic autonomy, open innovation, and sustained progress in safety and explainability underpin a new    â”‚
â”‚  era of AI impact. Widespread deployment across devices and languages, paired with scalable personalization and privacy,          â”‚
â”‚  broadens access and potential while mitigating risks. Organizations that integrate these advances will unlock unprecedented      â”‚
â”‚  productivity, insight, and global reach. The ongoing evolution of the AI LLM ecosystem promises to reshape industries, empower   â”‚
â”‚  individuals, and redefine how knowledge and intelligence are applied in the digital age.                                         â”‚
â”‚                                                                                                                                   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
ğŸš€ Crew: crew
â”œâ”€â”€ ğŸ“‹ Task: research_task (ID: d0325f3f-b890-4bf5-b973-f216ff60e939)
â”‚   Assigned to: AI LLMs Senior Data Researcher
â”‚   
â”‚   Status: âœ… Completed
â””â”€â”€ ğŸ“‹ Task: reporting_task (ID: aa65f26c-55ae-4d73-9cd6-4541403295c0)
    Assigned to: AI LLMs Reporting Analyst
    
    Status: âœ… Completed
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Task Completion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                                   â”‚
â”‚  Task Completed                                                                                                                   â”‚
â”‚  Name: reporting_task                                                                                                             â”‚
â”‚  Agent: AI LLMs Reporting Analyst                                                                                                 â”‚
â”‚                                                                                                                                   â”‚
â”‚  Tool Args:                                                                                                                       â”‚
â”‚                                                                                                                                   â”‚
â”‚                                                                                                                                   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Completion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                                   â”‚
â”‚  Crew Execution Completed                                                                                                         â”‚
â”‚  Name: crew                                                                                                                       â”‚
â”‚  ID: 92af3cd2-638e-4e6a-b014-54b7aafc216c                                                                                         â”‚
â”‚  Tool Args:                                                                                                                       â”‚
â”‚  Final Output: # 2025 AI LLM Landscape: In-Depth Report                                                                           â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 1. Multimodal LLMs Go Mainstream                                                                                              â”‚
â”‚                                                                                                                                   â”‚
â”‚  The year 2025 marks the full mainstream adoption of multimodal Large Language Models (LLMs), which now natively integrate text,  â”‚
â”‚  images, video, audio, and code within a unified architecture. Pioneering models such as GPT-5, Gemini Ultra, and the latest      â”‚
â”‚  offerings from OpenAI and Anthropic represent a transformative leap from text-only systems to truly universal models. These      â”‚
â”‚  models can seamlessly interpret, combine, and generate across diverse data types without requiring users to issue special        â”‚
â”‚  prompts or indicate the mode of information. For example, a physician can upload a radiology image, an audio dictation, and a    â”‚
â”‚  written case file, allowing the LLM to synthesize findings into a unified diagnostic report. In creative work, a user might ask  â”‚
â”‚  for a narrated storyboard with corresponding visuals and audio cues, all within a single conversational thread. This             â”‚
â”‚  convergence has made LLMs indispensable for multimedia content creation, data analysis, accessibility solutions, and real-world  â”‚
â”‚  task execution across industries.                                                                                                â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 2. Agentic LLMs & Autonomous Reasoning                                                                                        â”‚
â”‚                                                                                                                                   â”‚
â”‚  Modern LLMs are increasingly â€œagenticâ€â€”capable of autonomous reasoning, long-range planning, and dynamic interaction with        â”‚
â”‚  digital environments. Agentic LLMs can now devise multi-step plans, self-assess their actions, and execute complex workflows by  â”‚
â”‚  leveraging external APIs, web search, databases, and software tools. Key advances include toolformer models with integrated      â”‚
â”‚  plug-ins, self-correction and fallback mechanisms, as well as risk-based monitoring for operational safety. For instance, these  â”‚
â”‚  agentic models can automatically draft and send personalized email campaigns, analyze incoming responses, adapt messaging        â”‚
â”‚  strategies, and escalate exceptionsâ€”all with minimal human intervention. Safety protocols ensure that agentic LLMs reliably      â”‚
â”‚  handle web data, respect privacy boundaries, and maintain audit trails, making them suitable for high-stakes applications in     â”‚
â”‚  research, enterprise, and customer engagement.                                                                                   â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 3. Open-Source Advancements                                                                                                   â”‚
â”‚                                                                                                                                   â”‚
â”‚  Open-source LLMs have evolved rapidly, with Metaâ€™s Llama 3 and Mistralâ€™s Mixtral families delivering performance that matches    â”‚
â”‚  or exceeds major proprietary models on benchmarks of accuracy, efficiency, and adaptability. These models are released under     â”‚
â”‚  permissive licenses, fueling an explosion of grassroots contributions, community-driven research, and corporate adoption.        â”‚
â”‚  Open-source LLMs enable broader experimentation with model architectures, transparency, and custom deployment, lowering          â”‚
â”‚  barriers to innovation. This democratization of technology supports local language support, domain-specific tuning, and reduced  â”‚
â”‚  cost for startups and non-profit organizations. In 2025, government agencies, healthcare providers, and independent developers   â”‚
â”‚  increasingly rely upon open LLMs to craft solutions tailored to regional, ethical, and regulatory requirements.                  â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 4. Fine-Tuning and Customization at Scale                                                                                     â”‚
â”‚                                                                                                                                   â”‚
â”‚  The latest techniques in LLM specialization enable rapid, scalable, and secure adaptation for highly specific workflows or       â”‚
â”‚  domains. Differential Instruction Tuning allows LLMs to adjust to nuanced user instructions or evolving best practices without   â”‚
â”‚  full retraining. Reward Modeling integrates reinforcement learning from human or expert feedback to align LLM responses with     â”‚
â”‚  organizational values or compliance needs. Domain Adaptation leverages small, curated corpora or expert-in-the-loop corrections  â”‚
â”‚  for precision in fields such as finance, law, and medicine. These fine-tuning methods unlock state-of-the-art performance on     â”‚
â”‚  tailored tasksâ€”legal contract drafting, scientific literature review, or technical troubleshootingâ€”while preserving safety and   â”‚
â”‚  general language capabilities. Combined with improved data privacy protocols, this enables widespread enterprise and             â”‚
â”‚  vertical-market deployment.                                                                                                      â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 5. Ethics, Safety, and Alignment Breakthroughs                                                                                â”‚
â”‚                                                                                                                                   â”‚
â”‚  As LLMs increase in sophistication and reach, significant breakthroughs have occurred in ensuring ethical operation,             â”‚
â”‚  robustness, and user trust. Enhanced alignment strategiesâ€”such as Constitutional AI v2, which encodes explicit ethical           â”‚
â”‚  frameworks, and multi-agent oversight systemsâ€”provide continual safety checks and adversarial testing. Universal red-teaming     â”‚
â”‚  networks constantly probe for undesirable outputs. Built-in watermarking and robust traceability mechanisms attest to the        â”‚
â”‚  provenance and integrity of generated content. Improved explainability methods offer transparency into model decision-making,    â”‚
â”‚  facilitating responsible integration into regulated environments. As a result, rates of toxic, biased, or hallucinated outputs   â”‚
â”‚  have dropped precipitously, while accountability and compliance have risen, paving the way for safe, large-scale deployment.     â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 6. Real-Time Reasoning & Edge Deployment                                                                                      â”‚
â”‚                                                                                                                                   â”‚
â”‚  Advancements in both algorithms (e.g., sparse Transformers, quantization, retrieval-augmented generation) and hardware           â”‚
â”‚  (optimized AI accelerators) have enabled powerful LLMs to operate efficiently on edge devices. Smartphones, medical              â”‚
â”‚  instruments, autonomous machinery, and industrial IoT systems now run real-time LLM inference, preserving privacy, lowering      â”‚
â”‚  latency, and ensuring continuous operation even without cloud connectivity. For example, edge-deployed LLMs power intelligent    â”‚
â”‚  voice assistants, in-car navigation and diagnostics, and privacy-preserving wearable health monitors. These solutions are        â”‚
â”‚  resilient, highly available, and adapt to bandwidth or regulatory constraints, decentralizing AI and supporting new markets and  â”‚
â”‚  use cases.                                                                                                                       â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 7. Ultra-Long Context Windows                                                                                                 â”‚
â”‚                                                                                                                                   â”‚
â”‚  The expansion of LLM context windows to one million tokens (as in GPT-5 and Claude 3 Opus) has revolutionized how machines       â”‚
â”‚  process and connect information. These ultra-long context capabilities allow for the seamless ingestion and synthesis of entire  â”‚
â”‚  books, massive technical documentation, code repositories, full legal contracts, or multi-hour transcripts within a single       â”‚
â”‚  session. This fundamentally enhances long-form reasoning, document understanding, and persistent conversational memory. Use      â”‚
â”‚  cases include end-to-end review of clinical trials, comprehensive due diligence in finance, and lifelike, multi-session          â”‚
â”‚  personal assistants. The technical advances rely on memory-efficient inference and context-aware retrieval techniques,           â”‚
â”‚  maintaining high relevance, accuracy, and response times despite the scale.                                                      â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 8. AI-Powered Research & Discovery                                                                                            â”‚
â”‚                                                                                                                                   â”‚
â”‚  Modern LLMs have become essential assistants in scientific and engineering research, accelerating nearly every phase of the      â”‚
â”‚  discovery process. They autonomously generate hypotheses, aggregate and synthesize literature, design and simulate experiments,  â”‚
â”‚  analyze datasets, and draft publications. In pharmaceuticals, LLMs help identify new molecular structures, predict outcomes of   â”‚
â”‚  drug trials, and suggest modifications for increased efficacy. In climate science, they aid in modeling, scenario analysis, and  â”‚
â”‚  policy simulation. In mathematics and engineering, LLMs generate proofs, suggest optimization strategies, and support complex    â”‚
â”‚  design thinking. This synergy has shortened the cycle from research question to actionable insight, fueling rapid progress       â”‚
â”‚  across disciplines.                                                                                                              â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 9. Multilingual Capabilities and Global Expansion                                                                             â”‚
â”‚                                                                                                                                   â”‚
â”‚  State-of-the-art LLMs now deliver real-time, nuanced comprehension and generation in over 200 languagesâ€”covering regional        â”‚
â”‚  dialects, technical jargon, and cultural context. This profound multilingual ability breaks down language barriers for global    â”‚
â”‚  collaboration in education, commerce, healthcare, and government. Automated translation and summarization platforms,             â”‚
â”‚  globally-aware customer service agents, and context-sensitive educational tools empower individuals and businesses to            â”‚
â”‚  communicate fluidly across borders. For international partnerships and remote working environments, the LLMâ€™s ability to adapt   â”‚
â”‚  to local context and etiquette ensures effective, respectful, and precise interactions.                                          â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## 10. Personalization and Privacy                                                                                               â”‚
â”‚                                                                                                                                   â”‚
â”‚  The interplay of federated learning, on-device training, and privacy-preserving inference empowers users to maintain control     â”‚
â”‚  and confidentiality over their data while harnessing LLM personalization. Individuals and organizations can now tailor LLMs to   â”‚
â”‚  recognize specific terminologies, communication styles, interests, and proprietary knowledge, with all updates occurring         â”‚
â”‚  locally. Sensitive dataâ€”such as medical histories, financial information, and personal communicationsâ€”does not leave the userâ€™s  â”‚
â”‚  device, ensuring compliance with strict privacy regulations (e.g., GDPR, HIPAA). This private adaptation unlocks deeply          â”‚
â”‚  personalized AI-driven experiences: custom writing assistants, domain-specific advisors, and user-aware automation across        â”‚
â”‚  personal and professional domains.                                                                                               â”‚
â”‚                                                                                                                                   â”‚
â”‚  ---                                                                                                                              â”‚
â”‚                                                                                                                                   â”‚
â”‚  ## Conclusion                                                                                                                    â”‚
â”‚                                                                                                                                   â”‚
â”‚  The convergence of these ten trends has catapulted LLMs from experimental systems to omnipresent, transformative technologies    â”‚
â”‚  in 2025. Multimodality, agentic autonomy, open innovation, and sustained progress in safety and explainability underpin a new    â”‚
â”‚  era of AI impact. Widespread deployment across devices and languages, paired with scalable personalization and privacy,          â”‚
â”‚  broadens access and potential while mitigating risks. Organizations that integrate these advances will unlock unprecedented      â”‚
â”‚  productivity, insight, and global reach. The ongoing evolution of the AI LLM ecosystem promises to reshape industries, empower   â”‚
â”‚  individuals, and redefine how knowledge and intelligence are applied in the digital age.                                         â”‚
â”‚                                                                                                                                   â”‚
â”‚                                                                                                                                   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tracing Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                                                                   â”‚
â”‚  Info: Tracing is disabled.                                                                                                       â”‚
â”‚                                                                                                                                   â”‚
â”‚  To enable tracing, do any one of these:                                                                                          â”‚
â”‚  â€¢ Set tracing=True in your Crew/Flow code                                                                                        â”‚
â”‚  â€¢ Set CREWAI_TRACING_ENABLED=true in your project's .env file                                                                    â”‚
â”‚  â€¢ Run: crewai traces enable                                                                                                      â”‚
â”‚                                                                                                                                   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
âœ 
```

æœ€åæç¤ºæ²¡æœ‰å¼€å¯ tracingï¼Œå‚ç…§æç¤ºï¼Œä¿®æ”¹ .env æ–‡ä»¶ï¼ŒåŠ å…¥ä¸€è¡Œ:

```properties
CREWAI_TRACING_ENABLED=true
```

é‡æ–°æ‰§è¡Œï¼Œè¿™æ¬¡ä¼šæœ‰ tracing ä¿¡æ¯ï¼š


```bash
â”‚ âœ… Trace batch finalized with session ID: 5122e089-0d27-4d3d-839e-bd39da8e44a5                                                    â”‚
â”‚                                                                                                                                   â”‚
â”‚ ğŸ”— View here:                                                                                                                     â”‚
â”‚ https://app.crewai.com/crewai_plus/ephemeral_trace_batches/5122e089-0d27-4d3d-839e-bd39da8e44a5?access_code=TRACE-1e03614a69      â”‚
â”‚ ğŸ”‘ Access Code: TRACE-1e03614a69  
```

æ‰“å¼€æŸ¥çœ‹ tracing ä¿¡æ¯ï¼Œå°±ä¸¤æ¬¡ taskï¼Œä¸¤æ¬¡ LLM è°ƒç”¨ï¼š


![](images/tracing.png)